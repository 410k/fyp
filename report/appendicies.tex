\begin{appendices}
\appendix

\chapter{Sample ScienceIE Training/Test Document and Annotation}
\label{appendix:scienceiedataeg}
Presented is ScienceIE test paper file S221267161400105X.txt with accompanying annotations:\\

\noindent In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.\\

\noindent T1	Process 88 121	Scale-invariant feature transform\\
T2	Process 126 130	SIFT\\
T3	Process 157 183	Speeded up robust features\\
T4	Process 188 192	SURF\\
*	Synonym-of T1 T2\\
*	Synonym-of T3 T4\\
T5	Material 257 267	depth maps\\
T6	Process 398 420	Support vector machine\\
T7	Process 425 428	SVM\\
*	Synonym-of T6 T7\\
T8	Task 16 73	comparison between two popular feature extraction methods\\
T9	Process 332 355	Microsoft Kinect camera\\
T10	Process 492 495	SVM\\
T22	Task 47 65	feature extraction\\
T23	Process 441 455	classification\\
T27	Process 441 462	classification method\\
R2	Hyponym-of Arg1:T7 Arg2:T27\\

\chapter{Stop Words List}
\label{appendix:stopwords}
Below is the list of stop words used in this project:\\
\begin{multicols}{7}
\noindent !!\\
?!\\
??\\
!?\\
`\\
``\\
''\\
-lrb-\\
-rrb-\\
-lsb-\\
-rsb-\\
,\\
.\\
:\\
;\\
"\\
'\\
?\\
$<$\\
$>$\\
\{\\
\}\\
$[$\\
$]$\\
+\\
-\\
(\\
)\\
\&\\
\%\\
\$\\
@\\
!\\
\^\\
\#\\
*\\
..\\
...\\
'll\\
's\\
'm\\
a\\
about\\
above\\
after\\
again\\
against\\
all\\
am\\
an\\
and\\
any\\
are\\
aren't\\
as\\
at\\
be\\
because\\
been\\
before\\
being\\
below\\
between\\
both\\
but\\
by\\
can\\
can't\\
cannot\\
could\\
couldn't\\
did\\
didn't\\
do\\
does\\
doesn't\\
doing\\
don't\\
down\\
during\\
each\\
few\\
for\\
from\\
further\\
had\\
hadn't\\
has\\
hasn't\\
have\\
haven't\\
having\\
he\\
he'd\\
he'll\\
he's\\
her\\
here\\
here's\\
hers\\
herself\\
him\\
himself\\
his\\
how\\
how's\\
i\\
i'd\\
i'llv
i'm\\
i've\\
if\\
in\\
into\\
is\\
isn't\\
it\\
it's\\
its\\
itself\\
let's\\
me\\
more\\
most\\
mustn't\\
my\\
myself\\
no\\
nor\\
not\\
of\\
off\\
on\\
once\\
only\\
or\\
other\\
ought\\
our\\
ours\\
ourselves\\
out\\
over\\
own\\
same\\
shan't\\
she\\
she'd\\
she'll\\
she's\\
should\\
shouldn't\\
so\\
some\\
such\\
than\\
that\\
that's\\
the\\
their\\
theirs\\
them\\
themselves\\
then\\
there\\
there's\\
these\\
they\\
they'd\\
they'll\\
they're\\
they've\\
this\\
those\\
through\\
to\\
too\\
under\\
until\\
up\\
very\\
was\\
wasn't\\
we\\
we'd\\
we'll\\
we're\\
we've\\
were\\
weren't\\
what\\
what's\\
when\\
when's\\
where\\
where's\\
which\\
while\\
who\\
who's\\
whom\\
why\\
why's\\
with\\
won't\\
would\\
wouldn't\\
you\\
you'd\\
you'll\\
you're\\
you've\\
your\\
yours\\
yourself\\
yourselves\\
\#\#\#\\
return\\
arent\\
cant\\
couldnt\\
didnt\\
doesnt\\
dont\\
hadnt\\
hasnt\\
havent\\
hes\\
heres\\
hows\\
im\\
isnt\\
its\\
lets\\
mustnt\\
shant\\
shes\\
shouldnt\\
thats\\
theres\\
theyll\\
theyre\\
theyve\\
wasnt\\
were\\
werent\\
whats\\
whens\\
wheres\\
whos\\
whys\\
wont\\
wouldnt\\
youd\\
youll\\
youre\\
youve\\
\end{multicols}

\chapter{Google Scholar and ScienceDirect Search Pages}
\label{appendix:searcheg}
The following are screen shots of the query "computer science" being queried in two popular search engines: Google Scholar (left) and ScienceDirect (right). The "\textbf{$\cdot$$\cdot$$\cdot$}" denote some of the search results has been cropped out. As cropping has been applied, the results presented by Google Scholar and ScienceDirect are 10 and 25 (configurable to 50 or 100) respectively. \\

\includegraphics[width=\textwidth]{img/searchexamples.png}

\chapter{How to Run the Project from Source}
\label{appendix:howtorun}

To run the two applications, the following prerequisite steps must be taken:
\begin{enumerate}
	\item Install Java 8, Maven 3 and MySQL.
	\begin{itemize}
		\item Running \texttt{./install\_*.sh} in \texttt{resources/scripts} will do this for a system with \texttt{apt-get} available, such as Ubuntu.
	\end{itemize}
	\item Run the \texttt{env\_maven\_opts.sh} script in \texttt{resources/scripts} to setup required system environment variables.
	\item A Word2Vec model is needed. Based on this report, the pre-trained Google News model\footnote{\href{https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/}{https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/}} is recommended for download.
\end{enumerate}

\noindent Some files required by the system need pointing to. 
In terms of training and testing paper locations, checking the \texttt{paper.txt} and \texttt{test\_papers.txt} in the resource folders of both Java projects should reveal the paths used on the development system. The paths listed in this file are all processed unless they begin with a \texttt{\#}, and either point to a text file for processing, or a directory containing multiple text files for processing. Change these appropriately. 

Other components are more embedded in the Java code. Ideally a better solution to this should have been included by the developer, but unfortunately other tasks used up this time. Change \texttt{log4j2.xml:8} and \texttt{NlpObjectStore.java:23} to any folder where logs and serialised files can be saved. Change \texttt{Word2VecPretrained.java:11} to point to a Word2Vec model (either the Google News model or a model renamed to the same file descriptor).

To setup the MySQL database, navigate to \texttt{resources/sql}. Run, in order, \texttt{./setup.sh} and \texttt{./build.sh}. If you wish to use the final data made in this project run \texttt{./recover.sh}. Depending upon your MySQL configuration, you may need to change the password to be stronger. Finally, update \texttt{application.properties} in the FYP-GUI project's resource folder with the correct connection string and password.

Navigate to the root of the two Java projects (both in \texttt{java/}), and a series of useful scripts for compiling and running are presented: \\

\noindent \begin{tabular}{ l | p{3.5cm} | p{9cm} }
	\textbf{Java Project} & \textbf{Script} & \textbf{Description} \\
	\hline
	FYP-NLP & \texttt{./build.sh} & Compiles the system, without running any tests. \\
	\hline
	FYP-NLP & \texttt{./install.sh} & Compiles the system, without running any tests, and installs the project to the local Maven repository (required for building the FYP-GUI project). \\
	\hline
	FYP-NLP & \texttt{./test.sh $<$test class$>$} & Compiles the system and runs the JUnit test class given. Test classes can be found in \texttt{java/FYP-NLP/src/test/java/xyz/tomclarke/fyp/nlp}, and specifying the name of the class will run all test methods inside it without \texttt{@Ignore} above the \texttt{@Test} annotation.  \\
	\hline
	FYP-GUI & \texttt{./build.sh} & Compiles the GUI and runs all JUnit tests. \\
	\hline
	FYP-GUI & \texttt{./build-and-run.sh} & Compiles the GUI, without running any tests, and launches the GUI. \\
	\hline
	FYP-GUI & \texttt{./run.sh} & Launches the GUI (assumes it is already built). \\
\end{tabular}

\end{appendices}
